#           /\              Make sure to
#          /  \             replicate the ones
#         / || \            you need on Cloud Run
#        /  ||  \           also in your
#       /   ||   \          .env.yaml file
#      /    ..    \         so that it also works
#     /____________\        on Cloud Run

# ============================================================
# XPLAIN - Environment Variables (SHARE THIS FILE)
# Everyone should copy this file to ".env" locally (gitignored).
# ============================================================


# ----------------------------
# Storage locations (only if you use it)
# ----------------------------
# In this repo, we use LOCAL_MODEL_DIR for BLIP checkpoints.
# Keep these commented unless you later introduce data-loading utilities.
# LOCAL_DATA_PATH=raw_data
# LOCAL_REGISTRY_PATH=models


# ----------------------------
# Data source (only if you use it)
# ----------------------------
# Not used right now (inference-only).
# DATA_SOURCE=local
# MODEL_TARGET=local


# ----------------------------
# GCP Project (placeholders only)
# ----------------------------
# These are NOT required for local inference.
# They are here only to be Cloud-Run ready later.
GCP_PROJECT=project-id-123456
GCP_REGION=europe-west1

# IMPORTANT:
# We do NOT handle authentication in this repo.
# Whoever deploys later will manage service accounts on their side.
# GOOGLE_APPLICATION_CREDENTIALS=credentials.json


# ----------------------------
# Cloud Storage placeholders (future)
# ----------------------------
# Not used right now unless a deployment branch adds download logic.
# BUCKET_NAME=your-bucket-name
# RAW_DATA_LOCATION=raw_data
# MODELS_LOCATION=models

# Optional future model URI (NOT directly loadable by BLIP).
# Later Cloud Run container will download to LOCAL_MODEL_DIR first.
# GCS_MODEL_URI=gs://your-bucket/path/to/cxiu_blip_baseline


# ----------------------------
# BigQuery placeholders (future)
# ----------------------------
# BQ_REGION=EU
# DATASET=your_dataset


# ----------------------------
# Compute Engine placeholders (future)
# ----------------------------
# INSTANCE=instance_name


# ----------------------------
# Model Lifecycle placeholders (future)
# ----------------------------
# MLFLOW_TRACKING_URI=https://mlflow.lewagon.ai
# MLFLOW_EXPERIMENT=project_name_experiment_<user.github_nickname>
# MLFLOW_MODEL_NAME=project_name_<user.github_nickname>


# ============================================================
# >>> BLIP BASELINE INFERENCE SETTINGS (USED NOW)
# ============================================================

# ----------------------------
# 1) Model selection
# ----------------------------
# Model family switch (future-proofing)
MODEL_FAMILY=blip

# Hugging Face fallback model id
# Used if no valid local checkpoint folder is found.
HF_MODEL_NAME=Salesforce/blip-image-captioning-base


# ----------------------------
# 2) Local model folder (baseline)
# ----------------------------
# Your BLIP baseline was saved with save_pretrained(...),
# so LOCAL_MODEL_DIR MUST point to the folder containing config.json.
#
# Recommended explicit path:
LOCAL_MODEL_DIR=models/cxiu_blip_baseline
#
# If you prefer auto-discovery inside "models/", set:
# LOCAL_MODEL_DIR=models


# ----------------------------
# 3) Inference settings
# ----------------------------
# auto = use GPU if available, else CPU
DEVICE=auto

# Baseline spirit (your training used MAX_LENGTH=128)
MAX_NEW_TOKENS=128

# Beam width (you used 3 for qualitative examples)
BEAM_SIZE=3


# ----------------------------
# 4) Logging
# ----------------------------
LOG_LEVEL=INFO


# ----------------------------
# Docker (used later)
# ----------------------------
DOCKER_LOCAL_PORT=8080
DOCKER_REPO_NAME=docker
DOCKER_IMAGE_NAME=api
